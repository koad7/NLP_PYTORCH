{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koad7/NLP_PYTORCH/blob/main/Semantic_claim_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90_59tGXJItc"
      },
      "source": [
        "In this notebook we will build a semantic search engine for fact-checked claims using BERT. The overall approach will be to:\n",
        "1. Create a fine-tuned version of BERT that is able to produce claim embeddings in such a way that semantically similar claims are close to each other in the embedding space.\n",
        "2. Use the BERT claim encoder to create an index for a dataset of fact-checked claims and use it to find claims.\n",
        "\n",
        "\n",
        "**Remember to use a runtime with GPU**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfmnS33AJ94h"
      },
      "source": [
        "# Train a Semantic Claim Encoder\n",
        "As explained above, we want to train a deep learning model that is capable of:\n",
        "* given a claim $c$, produce an embedding for that claim $v_c$ in such a way that:\n",
        " * if $c_1$ and $c_2$ are semantically similar (e.g. they are paraphrases of each other), then $f_{dist}(v_{c_1}, v_{c_2}) \\approx 0$ for some distance function $f_{dist}$.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frjXPRXHTyBM"
      },
      "source": [
        "## Training Dataset: STS-B\n",
        "Fortunately, the [SemEval](https://aclweb.org/aclwiki/SemEval_Portal) series of workshops/challenges have produce many tasks that aim to test exactly such *semantic similarity*.\n",
        "\n",
        "[Various of these SemEval task datasets have been bundled together](http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark) into what is known as the **STS-B: Semantic Textual Similarity Benchmark**, which is part of the [GLUE collection of NLP benchmark datasets](https://gluebenchmark.com/tasks).\n",
        "\n",
        "STS-B consists of pairs of sentences which have been manually rated on a scale between $0$ (no semantic similarity) and $5$ semantically equivalent.\n",
        "\n",
        "We can download and load the dataset into a pandas `DataFrame`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUu_SMMqIz_c",
        "outputId": "b6fe5e9e-7b06-436c-cad5-88c8e53ed1bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "!wget http://ixa2.si.ehu.es/stswiki/images/4/48/Stsbenchmark.tar.gz\n",
        "!tar -xzf Stsbenchmark.tar.gz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-06 17:13:42--  http://ixa2.si.ehu.es/stswiki/images/4/48/Stsbenchmark.tar.gz\n",
            "Resolving ixa2.si.ehu.es (ixa2.si.ehu.es)... 158.227.106.100\n",
            "Connecting to ixa2.si.ehu.es (ixa2.si.ehu.es)|158.227.106.100|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 409630 (400K) [application/x-gzip]\n",
            "Saving to: ‘Stsbenchmark.tar.gz’\n",
            "\n",
            "Stsbenchmark.tar.gz 100%[===================>] 400.03K   606KB/s    in 0.7s    \n",
            "\n",
            "2019-10-06 17:13:43 (606 KB/s) - ‘Stsbenchmark.tar.gz’ saved [409630/409630]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo934bkNNqyj"
      },
      "source": [
        "Unfortunately, we cannot use the standard pandas `read_csv` method, because some lines in the csv have additional fields which are not well documented and cause the pandas parser to fail.. we implement our own:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-UaY1jkNm7c"
      },
      "source": [
        "import pandas as pd\n",
        "def read_sts_csv(path, columns=['source', 'type', 'year', 'id', 'score', 'sent_a', 'sent_b']):\n",
        "  rows = []\n",
        "  with open(path, mode='r', encoding='utf-8') as f:\n",
        "    lines = f.readlines()\n",
        "    print('Reading', len(lines), 'lines from', path)\n",
        "    for lnr, line in enumerate(lines):\n",
        "      cols = line.split('\\t')\n",
        "      assert len(cols) >= 7, 'line %s has %s columns instead of %s:\\n\\t%s' % (\n",
        "          lnr, len(cols), 7, \"\\n\\t\".join(cols)\n",
        "      )\n",
        "      cols = cols[:7]\n",
        "      assert len(cols) == 7\n",
        "      rows.append(cols)\n",
        "  result = pd.DataFrame(rows, columns=columns)\n",
        "  # score is read as a string, so add a copy with correct type\n",
        "  result['score_f'] = result['score'].astype('float64')\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIFpl19ZNzNy",
        "outputId": "a0d3522c-db98-4a54-e38d-31f269ab3965",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "sts_dev_df = read_sts_csv('stsbenchmark/sts-dev.csv')\n",
        "sts_train_df = read_sts_csv('stsbenchmark/sts-train.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading 1500 lines from stsbenchmark/sts-dev.csv\n",
            "Reading 5749 lines from stsbenchmark/sts-train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yA0yMX5mN27L"
      },
      "source": [
        "You can explore the dataset by looking at a small sample:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PN-6NWkN0-r",
        "outputId": "895dc4ac-83f3-4dcc-ea83-caa2b4f81b2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "sts_train_df.sample(n=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>type</th>\n",
              "      <th>year</th>\n",
              "      <th>id</th>\n",
              "      <th>score</th>\n",
              "      <th>sent_a</th>\n",
              "      <th>sent_b</th>\n",
              "      <th>score_f</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3946</th>\n",
              "      <td>main-news</td>\n",
              "      <td>headlines</td>\n",
              "      <td>2013</td>\n",
              "      <td>0243</td>\n",
              "      <td>2.4</td>\n",
              "      <td>2 Traffic Accidents Leave 47 Dead in China</td>\n",
              "      <td>3 traffic accidents leave 56 dead in China\\n</td>\n",
              "      <td>2.400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4836</th>\n",
              "      <td>main-news</td>\n",
              "      <td>headlines</td>\n",
              "      <td>2014</td>\n",
              "      <td>0606</td>\n",
              "      <td>5</td>\n",
              "      <td>China's new PM rejects US hacking claims</td>\n",
              "      <td>China Premier Li rejects 'groundless' US hacki...</td>\n",
              "      <td>5.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4794</th>\n",
              "      <td>main-news</td>\n",
              "      <td>headlines</td>\n",
              "      <td>2014</td>\n",
              "      <td>0555</td>\n",
              "      <td>2.6</td>\n",
              "      <td>West hails Syria opposition vote to join peace...</td>\n",
              "      <td>Syrian opposition to name delegation for talks\\n</td>\n",
              "      <td>2.600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3281</th>\n",
              "      <td>main-news</td>\n",
              "      <td>MSRpar</td>\n",
              "      <td>2012train</td>\n",
              "      <td>0508</td>\n",
              "      <td>4.333</td>\n",
              "      <td>\"PNC regrets its involvement\" in the deals, Ch...</td>\n",
              "      <td>James Rohr, chairman and chief executive offic...</td>\n",
              "      <td>4.333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5534</th>\n",
              "      <td>main-news</td>\n",
              "      <td>headlines</td>\n",
              "      <td>2015</td>\n",
              "      <td>1460</td>\n",
              "      <td>1.80</td>\n",
              "      <td>FAA continues ban on US flights to Tel Aviv</td>\n",
              "      <td>FAA lifts ban on U.S. flights to Tel Aviv\\n</td>\n",
              "      <td>1.800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         source  ... score_f\n",
              "3946  main-news  ...   2.400\n",
              "4836  main-news  ...   5.000\n",
              "4794  main-news  ...   2.600\n",
              "3281  main-news  ...   4.333\n",
              "5534  main-news  ...   1.800\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1FcTHUYOIgk"
      },
      "source": [
        "## Load the BERT model\n",
        "We will use BERT as a starting point, since it's the current state of the art in deep learning architectures for NLP tasks, and is a representative of a Transformer-based deep learning models. The advantage of using BERT is that it has already been pre-trained on a large corpus, so we only need to *fine-tune it* on the STS-B dataset.\n",
        "\n",
        "We will use the [Hugginface Pytorch-Transformers](https://github.com/huggingface/pytorch-transformers) library as an interface to the BERT model. We can install it on our environment, as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzEMQselN_-7",
        "outputId": "f5dad421-1c8a-4a04-aa80-2f86a3fc2b7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        }
      },
      "source": [
        "!pip install pytorch-transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.16.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.21.0)\n",
            "Collecting sacremoses (from pytorch-transformers)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 44.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.9.236)\n",
            "Collecting sentencepiece (from pytorch-transformers)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 39.1MB/s \n",
            "\u001b[?25hCollecting regex (from pytorch-transformers)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/a6/99eeb5904ab763db87af4bd71d9b1dfdd9792681240657a4c0a599c10a81/regex-2019.08.19.tar.gz (654kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 45.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.2.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2019.9.11)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (0.13.2)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.236 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.12.236)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.2.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.236->boto3->pytorch-transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.236->boto3->pytorch-transformers) (2.5.3)\n",
            "Building wheels for collected packages: sacremoses, regex\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=164db9654f57560c87c8cfae6174264538843be8aea5d6abf0e4d44e7475b9a2\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2019.8.19-cp36-cp36m-linux_x86_64.whl size=609229 sha256=854f963619674503d662b858a342e652fe25d7036bdcbcb9fe0dc09ca46330a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/04/07/b5010fb816721eb3d6dd64ed5cc8111ca23f97fdab8619b5be\n",
            "Successfully built sacremoses regex\n",
            "Installing collected packages: sacremoses, sentencepiece, regex, pytorch-transformers\n",
            "Successfully installed pytorch-transformers-1.2.0 regex-2019.8.19 sacremoses-0.0.35 sentencepiece-0.1.83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWXQIM_RQW4E"
      },
      "source": [
        "Now we can import various libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-kKKmnZQU_O"
      },
      "source": [
        "import torch\n",
        "from pytorch_transformers import *\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGlEw2YZQfkk"
      },
      "source": [
        "And we can load BERT, which consists of two main parts:\n",
        "1. the **model** itself, it:\n",
        " * receives as input a sequence of *token ids* according to a vocabulary defined during pre-training\n",
        " * has an initial embedding layer that combines non-contextual and positional embeddings and\n",
        " * $n$ Transformer layers (seq 2 seq), which produce contextual embeddings for the input tokens of increasing complexity.\n",
        "2. a **tokenizer** that converts the input sentence into a sequence of *token ids*\n",
        " * BERT (and other Transformer-based architectures) usually tokenize the input sentence based on wordpieces or subword units. See the [sentencepiece](https://github.com/google/sentencepiece) repo for more information about variants.\n",
        " * as part of the tokenization, BERT (and other models) adds special tokens that help the model understand where sentences begin and end; useful during training.\n",
        "\n",
        "BERT has two main variants `base` (has 12 layers) and `large` (24 layers). In this notebook we will use the `bert-base-cased` variant, but feel free to [explore alternative pre-trained models](https://huggingface.co/transformers/pretrained_models.html).\n",
        "\n",
        "We load the tokenizer and the model as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tWswprzQeMV"
      },
      "source": [
        "bert_model_name = 'bert-base-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_model_name, do_lower_case=False)\n",
        "bert = BertModel.from_pretrained(bert_model_name, output_hidden_states=True)\n",
        "if torch.cuda.is_available():\n",
        "  bert = bert.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp2-PeXHT7jN"
      },
      "source": [
        "### Implement function to produce sentence encodings based on the model\n",
        "\n",
        "Now that we have the bert tokenizer and model, we can pass it a sentence, but we need to define which output of BERT we want to use as the sentence embedding. We have several options:\n",
        " * input sequences are pre-prended with a special token `[cls]` which is meant to be used for classification of the sequence.\n",
        " * we can combine the final layer of contextual embeddings, e.g. by concatenating or pooling them (take the sum or average).\n",
        " * we can combine any combination of layers (e.g. the final 4 layers).\n",
        "\n",
        "Also, since the model and tokenizer need to be used together, we define a `tok_model` dict that we can pass to the function. We'll split the implementation into the following methods:\n",
        "1. `pad_encode` creates token ids of a uniform sequence length for a given sentence\n",
        "2. `tokenize` tokenizes a batch of sentences and produces a tensor that can be fed to the model\n",
        "3. `embedding_from_bert_output` produces a sentence embedding from the outputs of a BERT model, based on some encoding strategy\n",
        "3. `calc_sent_emb` receives a list of sentences and produces a tensor of sentence embeddings. Orchestrates by calling the other methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ywAkY1JTZM0"
      },
      "source": [
        "def pad_encode(text, tokenizer, max_length=50):\n",
        "  \"\"\"creates token ids of a uniform sequence length for a given sentence\"\"\"\n",
        "  tok_ids = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text))\n",
        "  tok_ids2 = tokenizer.add_special_tokens_single_sentence(tok_ids)\n",
        "  att_mask = [1 for _ in tok_ids2]\n",
        "  n_spectoks = len(tok_ids2) - len(tok_ids)\n",
        "  if len(tok_ids2) > max_length: # need to truncate\n",
        "    #print('Truncating from', len(tok_ids2))\n",
        "    n_to_trunc = len(tok_ids2) - max_length\n",
        "    tok_ids2 = tokenizer.add_special_tokens_single_sentence(tok_ids[:-n_to_trunc])\n",
        "    att_mask = [1 for _ in tok_ids2]\n",
        "  elif len(tok_ids2) < max_length: # need to pad\n",
        "    padding = []\n",
        "    for i in range(len(tok_ids2), max_length):\n",
        "      padding.append(tokenizer.pad_token_id)\n",
        "    att_mask += [0 for _ in padding]\n",
        "    tok_ids2 = tok_ids2 + padding\n",
        "  assert len(tok_ids2) == max_length\n",
        "  assert len(att_mask) == max_length\n",
        "  return tok_ids2, att_mask\n",
        "\n",
        "def tokenize_batch(sentences, tok_model, max_len=50, debug=False):\n",
        "  assert type(sentences) == list\n",
        "  encoded = [pad_encode(s, tokenizer=tok_model['tokenizer'],\n",
        "                        max_length=max_len)[0] for s in sentences]\n",
        "  att_masks = [pad_encode(s, tokenizer=tok_model['tokenizer'],\n",
        "                        max_length=max_len)[1] for s in sentences]\n",
        "  input_ids = torch.tensor(encoded)\n",
        "  att_masks = torch.tensor(att_masks)\n",
        "  if debug: print(input_ids.shape)\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "    input_ids = input_ids.cuda()\n",
        "    att_masks = att_masks.cuda()\n",
        "  return input_ids, att_masks\n",
        "\n",
        "def embedding_from_bert_output(bert_output, strategy=\"pooled\"):\n",
        "  \"\"\"Given the output tensor from a BERT model, return embeddings for the batch.\n",
        "  :param strategy can be:\n",
        "    1. a tuple (\"reduce_mean_layer\", n) where n is the index of the layer in model\n",
        "    2. a tuple (\"layer\", n)\n",
        "    2. \"pooled\" returns the default pooled embedding for the model. E.g. for BERT,\n",
        "      this is the last output for token [CLS]\n",
        "  \"\"\"\n",
        "  assert len(bert_output) == 3, \"Expecting 3 outputs, make sure model outputs hidden states\"\n",
        "  last_layer, pooled, hidden_layers = bert_output\n",
        "  if strategy == \"pooled\":\n",
        "    return pooled\n",
        "  if not type(strategy) == tuple:\n",
        "    raise ValueError(\"Expecting a tuple, but found %s \" % (type(strategy)))\n",
        "  strat_name, strat_val = strategy\n",
        "  if strat_name == \"reduce_mean_layer\":\n",
        "    layer_index = strat_val\n",
        "    layer_to_pool = hidden_layers[layer_index]\n",
        "    pooled_layer = torch.sum(layer_to_pool, dim=1) / (layer_to_pool.shape[1] + 1e-10)\n",
        "    if debug: print('pooled layer %s of %s' % (layer_index, len(hidden_layers)),\n",
        "                    pooled_layer.shape,\n",
        "                    'pooled from', layer_to_pool.shape)\n",
        "    return pooled_layer\n",
        "  if strat_name == \"layer\":\n",
        "    layer_index = strat_val\n",
        "    return hidden_layers[layer_index]\n",
        "  raise ValueError(\"Unsupported strategy %s \" % strategy)\n",
        "\n",
        "def calc_sent_emb(sentences, tok_model, strategy=\"pooled\", seq_len=50, debug=False):\n",
        "  \"\"\"Returns the embeddings for the input sentences, based on the `tok_model`\n",
        "  :param tok_model dict with keys `tokenizer` and `model`\n",
        "  :param strategy see `embedding_from_bert_output`\n",
        "  \"\"\"\n",
        "  input_ids, att_masks = tokenize_batch(sentences, tok_model, debug=debug, max_len=seq_len)\n",
        "\n",
        "  model = tok_model['model']\n",
        "  model.eval() # needed to deactivate any Dropout layers\n",
        "\n",
        "  with torch.no_grad():\n",
        "    model_out = model(input_ids, attention_mask=att_masks)\n",
        "\n",
        "  return embedding_from_bert_output(model_out, strategy)\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yU5qSe-usuQk"
      },
      "source": [
        "#### Play around with the model and encoder\n",
        "If you want, before starting to train the model, now's a good time to explore the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsXu7JdvskAV"
      },
      "source": [
        "bert_tok_model = {'tokenizer': tokenizer, \"model\": bert}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dZy6sPItRtl"
      },
      "source": [
        "For example, see what the tokenizer does to an input text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvJNeaE7tPZC",
        "outputId": "b168d034-a3b5-4f0b-f7eb-0a6ddbb4c294",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tokenizer.tokenize(\"Here is some text to encode\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Here', 'is', 'some', 'text', 'to', 'en', '##code']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JgKJMbutcTA"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67l4cPLVta0V",
        "outputId": "d9d7f003-2545-45d5-d4ed-edadf5a7815f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pad_encode(\"Here is some text to encode\", tokenizer, max_length=12)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101, 3446, 1110, 1199, 3087, 1106, 4035, 13775, 102, 0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIFEiy6ptpe-",
        "outputId": "6607e9c0-42c7-492f-d0c1-8d0a01adfe46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "calc_sent_emb(['Here is some text to encode', 'Here is another text'], tok_model=bert_tok_model).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vF4VbDllt4SZ"
      },
      "source": [
        "### Define Pytorch Encoder Module for fine-tuning\n",
        "The pre-trained BERT is optimized to predict masked tokens or the next sentence in a pair of sentences. This means that we cannot expect the pre-trained BERT to perform well in our task of semantic similarity. Therefore, we need to fine-tune the model.\n",
        "\n",
        "In pytorch, we can do this by defining a pytorch `Module` as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sb8RsQk8t2V3"
      },
      "source": [
        "class BERT_Finetuned_Encoder(torch.nn.Module):\n",
        "  def __init__(self,\n",
        "               bert_model_name='bert-base-cased',\n",
        "               pooling_strategy=\"pooled\",\n",
        "               train_from_layer=6,\n",
        "               seq_len=50):\n",
        "    super(BERT_Finetuned_Encoder, self).__init__()\n",
        "    tokenizer = BertTokenizer.from_pretrained(bert_model_name, do_lower_case=False)\n",
        "    bert_model=BertModel.from_pretrained(bert_model_name, output_hidden_states=True)\n",
        "    if train_from_layer is not None:\n",
        "      assert type(train_from_layer) == int\n",
        "      assert train_from_layer >= 0 and train_from_layer <= len(bert_model.encoder.layer)\n",
        "      print(\"Freezing wordpiece embeddings\")\n",
        "      for param in bert_model.embeddings.parameters():\n",
        "        param.requires_grad = False\n",
        "      for i, layer in enumerate(bert_model.encoder.layer):\n",
        "        if i < train_from_layer:\n",
        "          print(\"Freezing layer\", i)\n",
        "          for param in layer.parameters():\n",
        "            param.requires_grad = False\n",
        "        else:\n",
        "          print(\"Trainable layer\", i)\n",
        "      print(\"Trainable pooling layer\") # pooler layer is always trained\n",
        "    self.tokenizer = tokenizer\n",
        "    self.bert_model = bert_model\n",
        "    self.pooling_strategy = pooling_strategy\n",
        "    self.seq_len = seq_len\n",
        "\n",
        "    # power func parameters\n",
        "    self.min_val = 0.8\n",
        "    self.k = 1.0\n",
        "\n",
        "\n",
        "  def forward(self, sentences, sents_to_compare=None):\n",
        "    assert type(sentences) == list\n",
        "    if sents_to_compare is not None:\n",
        "      return self.predict_similarity(sentences, sents_to_compare)\n",
        "    else:\n",
        "      return self.encode(sentences)\n",
        "\n",
        "  def predict_encoded_similarity(self, semembs_as, semembs_bs):\n",
        "    cosim = F.cosine_similarity(semembs_as, semembs_bs) # (batch_size, 1)\n",
        "    # make prediction a value between 0.0 and 1.0\n",
        "    return self.power_fun_cosim2predfn(cosim)\n",
        "\n",
        "  def predict_similarity(self, sentsA, sentsB):\n",
        "    \"\"\"Predict pairwise similarity between two lists of sentences\n",
        "    Predicted values range from 0 (no similarity) and 1(semantically equal)\n",
        "    \"\"\"\n",
        "    assert type(sentsB) == list\n",
        "    assert len(sentsB) == len(sentsA)\n",
        "    #print('semembs_as', type(semembs_as))\n",
        "    return self.predict_encoded_similarity(\n",
        "        self.encode(sentsA), self.encode(sentsB))\n",
        "\n",
        "  def power_fun_cosim2predfn(self, cosim, min_val=0.8, k=25, steps=100):\n",
        "    \"\"\"Converts a cosine similarity result onto a value in range [0.0, 1.0] using\n",
        "    a non-linear mapping. This is useful because cosine similarities betweeen\n",
        "    vectors in embedding spaces are usually skewed towards a specific value.\"\"\"\n",
        "    assert min_val < 1.0\n",
        "    cosim_step = (1.0-min_val)/steps\n",
        "    val = torch.clamp(cosim, min=min_val, max=1.0)\n",
        "    step_i = (val - min_val)/cosim_step\n",
        "    pred = (step_i/steps)**k\n",
        "    assert len(pred.shape) == 1, pred.shape # (batch_size)\n",
        "    return torch.clamp(pred, min=0.0, max=1.0)\n",
        "\n",
        "  def linear_cosim2predfn(self, cosim):\n",
        "    \"\"\"Alternative mapping from a cosim tensor to a prediction range\n",
        "    Use `power_fun_cosim2predf` instead since it better aligns with the\n",
        "    distribution of cosine similarities.\n",
        "    \"\"\"\n",
        "    return (cosim + 1.0) / 2.0 # make prediction a value between 0.0 and 1.0\n",
        "\n",
        "  def encode(self, sentences):\n",
        "    # essentially the same as calc_sent_emb, but without explicitly setting model\n",
        "    #  for evaluation (since we can be in training mode)\n",
        "    input_ids, att_masks = tokenize_batch(sentences, {\"tokenizer\": self.tokenizer,\n",
        "         \"model\": self.bert_model}, max_len=self.seq_len)\n",
        "    model_out = self.bert_model(input_ids, attention_mask=att_masks)\n",
        "    return embedding_from_bert_output(model_out, self.pooling_strategy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UA4aBEkGzkGv"
      },
      "source": [
        "### Define training method\n",
        "\n",
        "We are now ready to define the main training loop. This is a pretty standard loop for PyTorch. The main thing here is that we:\n",
        " * iterate over batches of the STS-B dataset and produce encodings for both sentences.\n",
        " * then we calculate the cosine similarity between the two encodings and map that onto a predicted similarity score in a range between 0 and 1.\n",
        " * we use the STS-B value (normalised to the same range) to define a loss and train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eV4Bi7Kf0SNy"
      },
      "source": [
        "import time\n",
        "import copy\n",
        "from scipy import stats\n",
        "\n",
        "def train_semantic_encoder(semantic_encoder,\n",
        "                           dataloaders,\n",
        "                           optimizer, criterion, scheduler, num_epochs=25,\n",
        "                           device=\"cuda\"):\n",
        "  \"\"\" Trains a semantic encoder model\n",
        "  :param semantic_encoder maps a list of sentences onto a semantic embedding\n",
        "    space\n",
        "  :param dataloaders a dict with keys `train` and `val`, the values must be PyTorch\n",
        "    DataLoader instances providing STS-B item batches\n",
        "  :param cosim2predfn a function that maps a cosine similarity metric onto a\n",
        "    value in the range [0.0, 1.0]\n",
        "  \"\"\"\n",
        "  since = time.time()\n",
        "\n",
        "  assert getattr(semantic_encoder, 'state_dict', None) is not None, \"No model to train!!\"\n",
        "\n",
        "  def run_epoch(phase):\n",
        "    \"\"\"Execute a single epoch through the datasets.\n",
        "    :param phase can be `train` or `val`\n",
        "    returns a result dict with `loss` and `pearson`\n",
        "    \"\"\"\n",
        "\n",
        "    def run_step(sts_itembatch):\n",
        "      \"\"\"Execute a step in this epoch, ie process a batch.\n",
        "      Returns a triple with the batch (loss int, labels floats, predictions floats)\n",
        "      \"\"\"\n",
        "      #print('sts_itembatch', type(sts_itembatch))\n",
        "      sent_as = [item['sent_a'][0] for item in sts_itembatch]\n",
        "      sent_bs = [item['sent_b'][0] for item in sts_itembatch]\n",
        "      assert type(sent_as[0]) == str\n",
        "      label_scores = torch.tensor([float(item['score'][0]) for item in sts_itembatch])\n",
        "\n",
        "      label_scores = label_scores.to(device)\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      with torch.set_grad_enabled(phase == 'train'):\n",
        "        pred_score = semantic_encoder(sent_as, sent_bs)\n",
        "        loss = criterion(pred_score, label_scores/5.0) # make label between 0.0 and 1.0\n",
        "\n",
        "        if phase == 'train':\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "      return loss.item(), label_scores.tolist(), pred_score.tolist()\n",
        "\n",
        "    # run epoch:\n",
        "    if phase == 'train':\n",
        "      semantic_encoder.train()  # Set model to training mode\n",
        "    else:\n",
        "      semantic_encoder.eval()   # Set model to evaluate mode (important for Dropout layers)\n",
        "\n",
        "    running_loss, _label_scores, _pred_scores = 0.0, [], []\n",
        "    for sts_itembatch in dataloaders[phase]: # Iterate over data in epoch\n",
        "      batch_loss, batch_labels, batch_preds = run_step(sts_itembatch)\n",
        "      running_loss += batch_loss # * len(sts_itembatch) # update state\n",
        "      _label_scores += batch_labels\n",
        "      _pred_scores += batch_preds\n",
        "\n",
        "    if phase == 'val' and scheduler is not None:\n",
        "      scheduler.step(running_loss) #\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloaders[phase])\n",
        "    assert len(_label_scores) == len(_pred_scores), \"%s %s\" % (len(_label_scores), len(_pred_scores))\n",
        "    epoch_correl, p_val = stats.pearsonr(_label_scores, _pred_scores)\n",
        "    print('{} Loss: {:.4f}, Pearson: r={:.4f} p={:.4f} n={}'.format(\n",
        "        phase, epoch_loss, epoch_correl, p_val, len(_label_scores)))\n",
        "    return {\"loss\": epoch_loss,\n",
        "            \"pearson\": {\"r\": epoch_correl,\n",
        "                        \"p\": p_val,\n",
        "                        \"n\": len(_label_scores)}} # run_epoch\n",
        "\n",
        "  def is_better_result(current_best, new_val):\n",
        "    return new_val['pearson']['r'] > current_best['pearson']['r']\n",
        "\n",
        "  best_weights = copy.deepcopy(semantic_encoder.state_dict())\n",
        "  print('Validating initial model')\n",
        "  best_val = run_epoch('val') # run a validation epoch before the actual training\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "    print('-' * 10)\n",
        "\n",
        "    # Each epoch has a training and validation phase\n",
        "    for phase in ['train', 'val']:\n",
        "      epoch_result = run_epoch(phase)\n",
        "      if phase == 'val' and is_better_result(best_val, epoch_result):\n",
        "        best_val = epoch_result  # store state of best model\n",
        "        best_weights = copy.deepcopy(semantic_encoder.state_dict())\n",
        "    print()\n",
        "\n",
        "  time_elapsed = time.time() - since\n",
        "  print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "      time_elapsed // 60, time_elapsed % 60))\n",
        "  print('Best loss: {:4f} correl: {:.4f}'.format(best_val['loss'],\n",
        "                                                 best_val['pearson']['r']))\n",
        "\n",
        "  # load best model weights\n",
        "  semantic_encoder.load_state_dict(best_weights)\n",
        "  return semantic_encoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Esm1Jq_X2X1V"
      },
      "source": [
        "The `train_semantic_encoder` method expects the data to be provided via Pytorch' [Dataset](https://pytorch.org/docs/stable/data.html?highlight=dataset#torch.utils.data.Dataset) and [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) mechanisms, so we need to wrap our STS train and dev sets (at the moment a pandas `DataFrame`) into classes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3Pb7BbLy95a"
      },
      "source": [
        "import torch.utils.data\n",
        "import math\n",
        "\n",
        "class STSDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, sts_df, batch_size=20):\n",
        "    super(STSDataset).__init__()\n",
        "    self.sts_df = sts_df\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "  def __len__(self):\n",
        "    n_sents = self.sts_df.shape[0]\n",
        "    n_batch = n_sents/self.batch_size\n",
        "    result = math.ceil(n_batch)\n",
        "    return result\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    begin, end = index*self.batch_size, (index+1)*self.batch_size\n",
        "    values = self.sts_df[begin:end].values\n",
        "    result = []\n",
        "    for row in values:\n",
        "      result.append({col: row[i] for i, col in enumerate(self.sts_df.columns.values)})\n",
        "    return result\n",
        "\n",
        "  def __iter__(self):\n",
        "    raise NotImplementedError()\n",
        "    #return self.sts_df.iterrows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1WcIEbo302n"
      },
      "source": [
        "We are now ready to train the model, by defining the data loaders,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxUU8_iC0Gld"
      },
      "source": [
        "dataloaders = {'train': torch.utils.data.DataLoader(STSDataset(sts_train_df, batch_size=64)),\n",
        "               'val': torch.utils.data.DataLoader(STSDataset(sts_dev_df, batch_size=64))}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM07OJlj4CbM"
      },
      "source": [
        "the model to fine-tune:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wydh_kS739Wz",
        "outputId": "afd7e1c4-e8cd-468d-b722-05651b57460e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "bert_finetuned_semencoder = BERT_Finetuned_Encoder(train_from_layer=8)\n",
        "if torch.cuda.is_available():\n",
        "  bert_finetuned_semencoder = bert_finetuned_semencoder.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Freezing wordpiece embeddings\n",
            "Freezing layer 0\n",
            "Freezing layer 1\n",
            "Freezing layer 2\n",
            "Freezing layer 3\n",
            "Freezing layer 4\n",
            "Freezing layer 5\n",
            "Freezing layer 6\n",
            "Freezing layer 7\n",
            "Trainable layer 8\n",
            "Trainable layer 9\n",
            "Trainable layer 10\n",
            "Trainable layer 11\n",
            "Trainable pooling layer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xp5lQbs4YWz"
      },
      "source": [
        "the optimizer, starting the training (this can take about 10 minutes with a GPU):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lvp_5UjuFiqP",
        "outputId": "c4e617ee-4ffd-436b-9b8d-7c2ee576714c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(bert_finetuned_semencoder(['This is a sentence to encode']).shape)\n",
        "len([p for p in bert_finetuned_semencoder.parameters() if p.requires_grad])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 768])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcAyC4Pk4V40",
        "outputId": "6c6f6089-ef82-4a3d-9960-9c6ee87a9934",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        }
      },
      "source": [
        "# using learning rate for fine-tuning as suggested in BERT paper\n",
        "adam_optim = AdamW([p for p in bert_finetuned_semencoder.parameters() if p.requires_grad], lr=5e-5)\n",
        "\n",
        "bert_finetuned_semencoder = train_semantic_encoder(\n",
        "    bert_finetuned_semencoder,\n",
        "    dataloaders=dataloaders,\n",
        "    optimizer=adam_optim,\n",
        "    criterion=torch.nn.SmoothL1Loss(reduction='sum'), # also an option torch.nn.MSELoss(),\n",
        "    scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau(adam_optim),\n",
        "    num_epochs=5\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validating initial model\n",
            "val Loss: 4.1100, Pearson: r=0.2335 p=0.0000 n=1500\n",
            "Epoch 0/4\n",
            "----------\n",
            "train Loss: 3.0001, Pearson: r=0.2724 p=0.0000 n=5749\n",
            "val Loss: 2.0837, Pearson: r=0.6648 p=0.0000 n=1500\n",
            "\n",
            "Epoch 1/4\n",
            "----------\n",
            "train Loss: 1.6692, Pearson: r=0.6261 p=0.0000 n=5749\n",
            "val Loss: 1.8330, Pearson: r=0.7431 p=0.0000 n=1500\n",
            "\n",
            "Epoch 2/4\n",
            "----------\n",
            "train Loss: 1.2347, Pearson: r=0.7415 p=0.0000 n=5749\n",
            "val Loss: 1.8352, Pearson: r=0.7724 p=0.0000 n=1500\n",
            "\n",
            "Epoch 3/4\n",
            "----------\n",
            "train Loss: 1.0340, Pearson: r=0.7901 p=0.0000 n=5749\n",
            "val Loss: 1.7462, Pearson: r=0.7845 p=0.0000 n=1500\n",
            "\n",
            "Epoch 4/4\n",
            "----------\n",
            "train Loss: 0.8830, Pearson: r=0.8251 p=0.0000 n=5749\n",
            "val Loss: 1.6302, Pearson: r=0.7923 p=0.0000 n=1500\n",
            "\n",
            "Training complete in 11m 21s\n",
            "Best loss: 1.630164 correl: 0.7923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mhzf-App6btI"
      },
      "source": [
        "The output should be something like:\n",
        "```\n",
        "Validating initial model\n",
        "val Loss: 5.2647, Pearson: r=0.1906 p=0.0000 n=1500\n",
        "Epoch 0/5\n",
        "...\n",
        "Epoch 5/5\n",
        "...\n",
        "Training complete in 9m 20s\n",
        "Best loss: 1.688949 correl: 0.7717\n",
        "```\n",
        "\n",
        "Note that before training, we validate using the `dev` part of the dataset and achieve $r_{pearson}=0.1906$, which is what the pre-trained BERT produces. This shows that the default BERT embeddings are not very *semantic*, or at least not well-aligned with what humans regard as semantic similarity.\n",
        "\n",
        "The fine-tuned model should achieve a $r_{pearson}$ score close to $0.8$, which is much better aligned with human ratings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJiSvGi98Myy"
      },
      "source": [
        "# Create a semantic index of embeddings and explore it\n",
        "\n",
        "Now that we have a model for producing semantic embeddings of sentences, we can create a simple semantic index and define methods to populate and query it.\n",
        "\n",
        "Our semantic index is simply a python `dict` with fields `sent_encoder`, our semantic encoder, and `sent2emb` a `dict` from the sentence to its embedding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUNPsQABAAHO"
      },
      "source": [
        "  index = {\n",
        "      'sent_encoder': bert_finetuned_semencoder,\n",
        "      'sent2emb': {}\n",
        "  }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ONuPkdZFhyp"
      },
      "source": [
        "## Define a method to populate the index"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0lrSe4n8FWa"
      },
      "source": [
        "def populate_index(sentence_generator, index, debug=False):\n",
        "  \"\"\"Populates a semantic sentence index with sentences from a generator\n",
        "  Returns the `index` with the new embeddings.\"\"\"\n",
        "\n",
        "  def add_batch(index, batch):\n",
        "    with torch.no_grad():\n",
        "      batch_embs = index['sent_encoder'](batch)\n",
        "    assert batch_embs.shape[0] == len(batch)\n",
        "    for i, s in enumerate(batch):\n",
        "      index['sent2emb'][s] = batch_embs[i]\n",
        "\n",
        "  index['sent_encoder'].eval() # put into evaluation mode\n",
        "\n",
        "  batch = []\n",
        "  for snr, sentence in enumerate(sentence_generator):\n",
        "    batch.append(sentence)\n",
        "    if len(batch) > 32:\n",
        "      if debug: print('At', snr, \"processing batch..\", )\n",
        "      add_batch(index, batch)\n",
        "      batch = []\n",
        "  if len(batch) > 0:\n",
        "    add_batch(index, batch)\n",
        "\n",
        "  print('Index now has', len(index['sent2emb']), 'sentences')\n",
        "  return index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDuYbV7RF-TX"
      },
      "source": [
        "And a method to iterate over all the STS-B items in one of the `DataFrame`s we loaded at the beginning of the notebook:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HvOL5CV_a6f"
      },
      "source": [
        "def sts_df_as_sent_generator(df):\n",
        "  \"\"\"Create a sentence generator given a DataFrame with STS-B rows\"\"\"\n",
        "  for rnr, row in df.iterrows():\n",
        "    for s in [row['sent_a'], row['sent_b']]:\n",
        "      yield s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kPR6jHsGKBM"
      },
      "source": [
        "## Populate index with STS-B `dev`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QfoLCBABtxa",
        "outputId": "f6748be6-e545-4cf4-84f1-607d2b8c8f93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "index = populate_index(sts_df_as_sent_generator(sts_dev_df), index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index now has 2941 sentences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7_VdVmvFcOc"
      },
      "source": [
        "To explore the newly populated dataset, we can define a method to find the top k elements in the index for a given sentence:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u160LePsB20o"
      },
      "source": [
        "# do not trim the sentences in the pandas tables too much...\n",
        "pd.set_option('display.max_colwidth', 150)\n",
        "\n",
        "def find_most_similar(text, semb_index, k=5):\n",
        "  text_emb = semb_index['sent_encoder']([text])\n",
        "  if len(text_emb.shape) == 2:\n",
        "    text_emb = text_emb[0]\n",
        "  assert len(text_emb.shape) == 1, \"\" + str(text_emb.shape)\n",
        "  s2cosim = {}\n",
        "  for s, s_emb in semb_index['sent2emb'].items():\n",
        "    assert len(s_emb.shape) == 1, \"%s\" % (s_emb.shape)\n",
        "    s2cosim[s] = F.cosine_similarity(text_emb, s_emb, dim=0).item()\n",
        "  sorted_s2cosim = sorted(s2cosim.items(), key=lambda kv: kv[1], reverse=True)\n",
        "  results = [{'sentence': kv[0], 'cosim': kv[1]} for kv in sorted_s2cosim[:k]]\n",
        "  return pd.DataFrame(results).sort_values(by=['cosim'], ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB3cBVSAH9LC"
      },
      "source": [
        "### Explore the dataset using some examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URk1ZwpKIDkB"
      },
      "source": [
        "#### news about traffic accidents in China"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJRQdlRCG6XR",
        "outputId": "0dc4b508-58b6-4059-a735-ad56cfeae81a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "find_most_similar(\"3 traffic accidents leave 56 dead in China\", index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cosim</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.993376</td>\n",
              "      <td>'Around 100 dead or injured' after China earthquake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.992287</td>\n",
              "      <td>Hundreds dead or injured in China quake\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.990573</td>\n",
              "      <td>Floods leave six dead in Philippines</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.989853</td>\n",
              "      <td>At least 28 people die in Chinese coal mine explosion\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.989653</td>\n",
              "      <td>Heavy rains leave 18 dead in Philippines\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      cosim                                                 sentence\n",
              "0  0.993376      'Around 100 dead or injured' after China earthquake\n",
              "1  0.992287                Hundreds dead or injured in China quake\\n\n",
              "2  0.990573                     Floods leave six dead in Philippines\n",
              "3  0.989853  At least 28 people die in Chinese coal mine explosion\\n\n",
              "4  0.989653               Heavy rains leave 18 dead in Philippines\\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naxRrrY_IKPi"
      },
      "source": [
        "#### economic output in US"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh1Bqy84JYpv",
        "outputId": "e832ae23-d0be-4cbe-c229-b607da80dd90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "find_most_similar(\"US' industrial output growth slows to 9.2 pct in July\", index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cosim</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.997261</td>\n",
              "      <td>North American markets grabbed early gains Monday morning, as earnings season begins to slow and economic indicators take the spotlight.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.996923</td>\n",
              "      <td>North American markets finished mixed in directionless trading Monday as earnings season begins to slow and economic indicators move into the spot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.996634</td>\n",
              "      <td>S. Korean economic growth falls to near 3-year low\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.996336</td>\n",
              "      <td>The blue-chip Dow Jones industrial average .DJI climbed 164 points, or 1.91 percent, to 8,765.38, brushing its highest levels since mid-January.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.996165</td>\n",
              "      <td>That took the benchmark 10-year note US10YT=RR down 9/32, its yield rising to 3.37 percent from 3.34 percent late on Thursday.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      cosim                                                                                                                                               sentence\n",
              "0  0.997261             North American markets grabbed early gains Monday morning, as earnings season begins to slow and economic indicators take the spotlight.\\n\n",
              "1  0.996923  North American markets finished mixed in directionless trading Monday as earnings season begins to slow and economic indicators move into the spot...\n",
              "2  0.996634                                                                                                   S. Korean economic growth falls to near 3-year low\\n\n",
              "3  0.996336       The blue-chip Dow Jones industrial average .DJI climbed 164 points, or 1.91 percent, to 8,765.38, brushing its highest levels since mid-January.\n",
              "4  0.996165                         That took the benchmark 10-year note US10YT=RR down 9/32, its yield rising to 3.37 percent from 3.34 percent late on Thursday."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tx06rMiWJFNw"
      },
      "source": [
        "# Create another index for a Claims dataset\n",
        "So the results on STS-B `dev` seem OK. Now, let's create an index for a dataset of checked facts from [datacommons factcheck](https://www.datacommons.org/factcheck/download#research-data).\n",
        "\n",
        "First, let's download the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjQ7oMZ2IWMd",
        "outputId": "ef84aa63-f62a-445e-fe99-28bc9cc664d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "!wget https://storage.googleapis.com/datacommons-feeds/claimreview/latest/data.json\n",
        "!mv data.json datacommons-factcheck.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-06 17:37:51--  https://storage.googleapis.com/datacommons-feeds/claimreview/latest/data.json\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.76.128, 2a00:1450:400c:c08::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.76.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9801768 (9.3M) [application/json]\n",
            "Saving to: ‘data.json’\n",
            "\n",
            "data.json           100%[===================>]   9.35M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-10-06 17:37:51 (68.8 MB/s) - ‘data.json’ saved [9801768/9801768]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCRugl76Jtoj"
      },
      "source": [
        "## Load dataset into a pandas `DataFrame`\n",
        "This dataset is formatted using JSON-LD, so we can simply parse it as JSON"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k70rcCAJpeH"
      },
      "source": [
        "import json\n",
        "with open('datacommons-factcheck.json', mode='r', encoding='utf-8') as f:\n",
        "  js_datafeed = json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtsG8VNtKP8u"
      },
      "source": [
        "and define a method to convert the nested python `dict` into a pandas `DataFrame`. We are not interested in all the data in the json feed, so we only populate a few columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61TKBRn3J7vN"
      },
      "source": [
        "def load_datacommons_feed_df(js_datafeed):\n",
        "  claims = []\n",
        "  for feed_item in js_datafeed['dataFeedElement']:\n",
        "    claim_items = feed_item.get('item', [])\n",
        "    if claim_items is None:\n",
        "      claim_items = []\n",
        "    for claim_in_feed in claim_items:\n",
        "      claim = claim_in_feed.get('claimReviewed', None)\n",
        "      if claim is not None:\n",
        "        claims.append({\n",
        "          'claimReviewed': claim,\n",
        "          'reviewed_by': claim_in_feed.get('author', {}).get('name', 'unknown'),\n",
        "          'review_altName': claim_in_feed.get('reviewRating', {}).get('alternateName', \"\"),\n",
        "          'claim_date': claim_in_feed.get('itemReviewed', {}).get('datePublished', None),\n",
        "          'claimed_by': claim_in_feed.get('itemReviewed', {}).get('author', {}).get('name', None)\n",
        "        })\n",
        "  return pd.DataFrame(claims)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhdMLydHKq1a",
        "outputId": "3f1d19fa-5990-4e11-9166-9b8a13466b18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "claims_df = load_datacommons_feed_df(js_datafeed)\n",
        "claims_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5647, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04sydj9cK-2E",
        "outputId": "002a8e51-384c-4eb1-9132-ab8f7a206c3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        }
      },
      "source": [
        "claims_df.sample(n=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>claimReviewed</th>\n",
              "      <th>claim_date</th>\n",
              "      <th>claimed_by</th>\n",
              "      <th>review_altName</th>\n",
              "      <th>reviewed_by</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4409</th>\n",
              "      <td>“Sumber daya yang sebelumnya dikuasai asing, berhasil dikuasai oleh negara. [Blok] Mahakam, Rokan, Freeport sebagai contoh.“</td>\n",
              "      <td>2019-04-13</td>\n",
              "      <td>Joko Widodo dalam Debat Capres-Cawapres Kelima</td>\n",
              "      <td>Benar</td>\n",
              "      <td>Tempo.co</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1014</th>\n",
              "      <td>The push by Assembly Democrats seeking Americans with Disabilities Act accommodations for a lawmaker were timed to make Vos look bad as he became ...</td>\n",
              "      <td>2019-08-14</td>\n",
              "      <td>Robin Vos</td>\n",
              "      <td>False</td>\n",
              "      <td>PolitiFact</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5307</th>\n",
              "      <td>錯誤內容與截圖訊息來自中國網民討論內容，事實上完全沒有任何的根據，對於「國立故宮博物院2000件文物，將與日本100件文物互換，且雙方交換展期50年」，故宮澄清絕無此事。</td>\n",
              "      <td>2018-09-10</td>\n",
              "      <td>Charles Yeh</td>\n",
              "      <td>不實</td>\n",
              "      <td>MyGoPen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2285</th>\n",
              "      <td>The EU sends Northern Ireland €500 million a year</td>\n",
              "      <td>2019-05-08</td>\n",
              "      <td>SDLP leader, Colum Eastwood</td>\n",
              "      <td>ACCURATE WITH CONSIDERATION. The €500 million figure quoted by the SDLP is substantiated by European Commission figures for EU regional funding of...</td>\n",
              "      <td>Fact Check NI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>620</th>\n",
              "      <td>A claim that herdsmen walked into the terminal of Big Joe transport in Kogi and shot all passengers boarding to travel to Edo state.</td>\n",
              "      <td>2019-08-13</td>\n",
              "      <td>A Facebook Post</td>\n",
              "      <td>False</td>\n",
              "      <td>DUBAWA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                              claimReviewed  ...    reviewed_by\n",
              "4409                           “Sumber daya yang sebelumnya dikuasai asing, berhasil dikuasai oleh negara. [Blok] Mahakam, Rokan, Freeport sebagai contoh.“  ...       Tempo.co\n",
              "1014  The push by Assembly Democrats seeking Americans with Disabilities Act accommodations for a lawmaker were timed to make Vos look bad as he became ...  ...     PolitiFact\n",
              "5307                                                                  錯誤內容與截圖訊息來自中國網民討論內容，事實上完全沒有任何的根據，對於「國立故宮博物院2000件文物，將與日本100件文物互換，且雙方交換展期50年」，故宮澄清絕無此事。  ...        MyGoPen\n",
              "2285                                                                                                      The EU sends Northern Ireland €500 million a year  ...  Fact Check NI\n",
              "620                   A claim that herdsmen walked into the terminal of Big Joe transport in Kogi and shot all passengers boarding to travel to Edo state.   ...         DUBAWA\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-WnYVykLZzp"
      },
      "source": [
        "## Create claim iterator\n",
        "\n",
        "The datafeed contains claims in many different languages, and since our model only works for English, we should only take into account English claims. Unfortunately, the feed does not include a language tag, so we need to filter the feed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6lcutkILA1p",
        "outputId": "0b7d2cea-2892-4477-a832-db59ae44e4ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "!pip install langdetect"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/59/4bc44158a767a6d66de18c4136c8aa90491d56cc951c10b74dd1e13213c9/langdetect-1.0.7.zip (998kB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from langdetect) (1.12.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.7-cp36-none-any.whl size=993460 sha256=1098442956688161b1fb5efba9e29bf00c8d42654aaf5f774eb5b596c4926cb7\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/0c/a9/1647275e7ef5014e7b83ff30105180e332867d65e7617ddafe\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7EVyf0iL40n"
      },
      "source": [
        "from langdetect import detect\n",
        "\n",
        "def is_english(sentence):\n",
        "  try:\n",
        "    return detect(sentence) == 'en'\n",
        "  except:\n",
        "    # e.g. because sentence is empty\n",
        "    return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZYU__ZFMOSu",
        "outputId": "94ebf72f-1ae5-477f-ca7a-139d195a7935",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "is_english(\"Tin bài hàng đầu\"), is_english(\n",
        "    \"Claim: H Raja and S Ve Sekher supporters fighting in BJP TN office\"), is_english(\" \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(False, True, False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftOBYdoxMS6g"
      },
      "source": [
        "def claims_df_english_row_generator(df):\n",
        "  for rnr, row in df.iterrows():\n",
        "    s = row['claimReviewed']\n",
        "    if is_english(s):\n",
        "      yield row.to_dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTdWPAQoNyPC"
      },
      "source": [
        "## Populate a `claim_index`\n",
        "\n",
        "We could just reuse the `populate_index` we defined above, but we already have some interesting metadata about reviewed claims, so it's interesting to keep those in our index. So define a slightly modified version:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWPmHY2QQrWQ"
      },
      "source": [
        "def populate_claim_index(claim_rows, index, debug=False):\n",
        "  \"\"\"Populates a semantic sentence index with sentences from a generator\n",
        "  Returns the `index` with the new embeddings.\"\"\"\n",
        "\n",
        "  def add_batch(index, batch):\n",
        "    sent_batch = [row['claimReviewed'] for row in batch]\n",
        "    with torch.no_grad():\n",
        "      batch_embs = index['sent_encoder'](sent_batch)\n",
        "    assert batch_embs.shape[0] == len(batch)\n",
        "    for i, s in enumerate(sent_batch):\n",
        "      index['sent2emb'][s] = batch_embs[i]\n",
        "      index['claim_meta'][s] = {\n",
        "          'review_altName': batch[i]['review_altName'],\n",
        "          'reviewed_by': batch[i]['reviewed_by']\n",
        "          }\n",
        "\n",
        "  index['sent_encoder'].eval() # put into evaluation mode\n",
        "\n",
        "  batch = []\n",
        "  for snr, claim_row in enumerate(claim_rows):\n",
        "    batch.append(claim_row)\n",
        "    if len(batch) > 32:\n",
        "      if debug: print('At', snr, \"processing batch..\", )\n",
        "      add_batch(index, batch)\n",
        "      batch = []\n",
        "  if len(batch) > 0:\n",
        "    add_batch(index, batch)\n",
        "\n",
        "  print('Index now has', len(index['sent2emb']), 'sentences')\n",
        "  return index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHp5pPu3M4VP"
      },
      "source": [
        "claim_index = {\n",
        "      'sent_encoder': bert_finetuned_semencoder,\n",
        "      'sent2emb': {},\n",
        "      'claim_meta': {}\n",
        "  }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCez-MOkNft3",
        "outputId": "66bfdb08-9702-4b78-f890-ed317dee2f12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "claim_index = populate_claim_index(\n",
        "    claims_df_english_row_generator(claims_df), claim_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index now has 3519 sentences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV-ANt9qNpVU"
      },
      "source": [
        "## Explore dataset\n",
        "We define a custom version of `find_most_similar` to display more relevant info about the most similar claims:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEm7kUTPTLJV"
      },
      "source": [
        "def find_most_similar_claim(text, claim_index, k=5):\n",
        "  text_emb = claim_index['sent_encoder']([text]) # shape (1, emb_dim)\n",
        "  s2cosim = {}\n",
        "  s2pred = {}\n",
        "  for s, s_emb in claim_index['sent2emb'].items():\n",
        "    ts_emb = s_emb.unsqueeze(0) # shape (1, emb_dim)\n",
        "    pred_score = claim_index['sent_encoder'].predict_encoded_similarity(\n",
        "        text_emb, ts_emb)\n",
        "    #s2cosim[s] = F.cosine_similarity(text_emb, s_emb, dim=0).item()\n",
        "    s2pred[s] = pred_score.item()\n",
        "\n",
        "  #sorted_s2cosim = sorted(s2cosim.items(), key=lambda kv: kv[1], reverse=True)\n",
        "  sorted_s2pred = sorted(s2pred.items(), key=lambda kv: kv[1], reverse=True)\n",
        "  claim_meta = claim_index['claim_meta']\n",
        "  results = [{'claim': claim,\n",
        "              'true?': claim_meta[claim].get('review_altName', '??'),\n",
        "              'reviewed by': claim_meta[claim].get('reviewed_by', \"??\"),\n",
        "              'pred': pred,\n",
        "              #'cosim': cosim\n",
        "              #} for claim, cosim in sorted_s2cosim[:k]]\n",
        "              } for claim, pred in sorted_s2pred[:k]]\n",
        "\n",
        "  return pd.DataFrame(results).sort_values(by=['pred'], ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fDEmq40cFwg"
      },
      "source": [
        "### Brexit, UK"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZUZuSgrJzXm",
        "outputId": "a1512f9f-0e68-4913-c9c3-e31d84d01c66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "find_most_similar_claim(\"Most people in UK now want Brexit\", claim_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>claim</th>\n",
              "      <th>pred</th>\n",
              "      <th>reviewed by</th>\n",
              "      <th>true?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>77% of young people in the UK don’t want Brexit.</td>\n",
              "      <td>0.766278</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Inaccurate. Polls for Great Britain show support from those aged 18-24 for remaining in the EU at between 57% and 71%; for Northern Ireland, betwe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A claim that says Nigeria’s Independent National Electoral Commission [INEC] ban phones at polling stations</td>\n",
              "      <td>0.681251</td>\n",
              "      <td>DUBAWA</td>\n",
              "      <td>The claim that INEC has banned the use of phones and cameras at polling stations is NOT ENTIRELY FALSE. While you are not banned from going to the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The DUP at no point has ever agreed to establish an Irish Language Act with the UK government, with the Irish government, with Sinn Féin or anybod...</td>\n",
              "      <td>0.636494</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Accurate. The St Andrew’s Agreement committed the UK Government to an Irish Language Act, but subsequent legislation compelled the Northern Irelan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Says there could be a potential mass shooting at a Walmart nearby.</td>\n",
              "      <td>0.636324</td>\n",
              "      <td>PolitiFact</td>\n",
              "      <td>It's a widespread hoax message</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Claim video claiming muslims protesting in Kashmir after Eid prayers against article 370 dissolution</td>\n",
              "      <td>0.630145</td>\n",
              "      <td>Fact Crescendo</td>\n",
              "      <td>FALSE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                   claim  ...                                                                                                                                                  true?\n",
              "0                                                                                                       77% of young people in the UK don’t want Brexit.  ...  Inaccurate. Polls for Great Britain show support from those aged 18-24 for remaining in the EU at between 57% and 71%; for Northern Ireland, betwe...\n",
              "1                                            A claim that says Nigeria’s Independent National Electoral Commission [INEC] ban phones at polling stations  ...  The claim that INEC has banned the use of phones and cameras at polling stations is NOT ENTIRELY FALSE. While you are not banned from going to the...\n",
              "2  The DUP at no point has ever agreed to establish an Irish Language Act with the UK government, with the Irish government, with Sinn Féin or anybod...  ...  Accurate. The St Andrew’s Agreement committed the UK Government to an Irish Language Act, but subsequent legislation compelled the Northern Irelan...\n",
              "3                                                                                     Says there could be a potential mass shooting at a Walmart nearby.  ...                                                                                                                         It's a widespread hoax message\n",
              "4                                                   Claim video claiming muslims protesting in Kashmir after Eid prayers against article 370 dissolution  ...                                                                                                                                                  FALSE\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfp_cRYQcsPq"
      },
      "source": [
        "The predictions are what the model outputs, i.e. the range is between 0 (not similar at all) and 1 (semantically very similar). In this case, we see that a related, but narrower, claim was found with semantic similarity score of $0.76$. Other results are below $0.7$ and are not about Brexit at all."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPfwBhmGdTEE"
      },
      "source": [
        "### Northern Ireland and EU contributions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBmgmBZtJ7uQ",
        "outputId": "f767d47c-2790-4371-98b7-e4e36935d360",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        }
      },
      "source": [
        "find_most_similar_claim(\"Northern Ireland receives yearly half a billion pounds from the European Union\", claim_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>claim</th>\n",
              "      <th>pred</th>\n",
              "      <th>reviewed by</th>\n",
              "      <th>true?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The EU sends Northern Ireland €500 million a year</td>\n",
              "      <td>0.751983</td>\n",
              "      <td>Fact Check NI</td>\n",
              "      <td>ACCURATE WITH CONSIDERATION. The €500 million figure quoted by the SDLP is substantiated by European Commission figures for EU regional funding of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Northern Ireland is a net contributor to the EU.</td>\n",
              "      <td>0.746601</td>\n",
              "      <td>unknown</td>\n",
              "      <td>This claim is false, as we estimate that Northern Ireland was a net recipient of £74 million in the 2014/15 financial year. Others have claimed th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Arlene Foster, the leader of the Democratic Unionist Party, said that the party delivered “an extra billion pounds” for Northern Ireland.</td>\n",
              "      <td>0.735942</td>\n",
              "      <td>Fact Check NI</td>\n",
              "      <td>ACCURATE. The £1bn is specific to the jurisdiction of Northern Ireland and is in addition to funding pledged as a result of the Stormont House Agr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Northern Ireland were once net contributors of revenue to HM Treasury.</td>\n",
              "      <td>0.732447</td>\n",
              "      <td>unknown</td>\n",
              "      <td>True, up until the 1930s. But data show that Northern Ireland has run a fiscal deficit since 1966. The most recent figure, from 2013-14, is a subv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The number of homes in Northern Ireland that have had their housing supplementary payments removed has increased five times more in the past year.</td>\n",
              "      <td>0.731485</td>\n",
              "      <td>unknown</td>\n",
              "      <td>Accurate with considerations. The 140 households whose top-up payments ceased in the past year is four times more than the 35 households in the pr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                claim  ...                                                                                                                                                  true?\n",
              "0                                                                                                   The EU sends Northern Ireland €500 million a year  ...  ACCURATE WITH CONSIDERATION. The €500 million figure quoted by the SDLP is substantiated by European Commission figures for EU regional funding of...\n",
              "1                                                                                                    Northern Ireland is a net contributor to the EU.  ...  This claim is false, as we estimate that Northern Ireland was a net recipient of £74 million in the 2014/15 financial year. Others have claimed th...\n",
              "2           Arlene Foster, the leader of the Democratic Unionist Party, said that the party delivered “an extra billion pounds” for Northern Ireland.  ...  ACCURATE. The £1bn is specific to the jurisdiction of Northern Ireland and is in addition to funding pledged as a result of the Stormont House Agr...\n",
              "3                                                                              Northern Ireland were once net contributors of revenue to HM Treasury.  ...  True, up until the 1930s. But data show that Northern Ireland has run a fiscal deficit since 1966. The most recent figure, from 2013-14, is a subv...\n",
              "4  The number of homes in Northern Ireland that have had their housing supplementary payments removed has increased five times more in the past year.  ...  Accurate with considerations. The 140 households whose top-up payments ceased in the past year is four times more than the 35 households in the pr...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzIJh3NSdjvB"
      },
      "source": [
        "In this case we see tha the first two matches are on topic with scores above $0.74$. Notice that *the only words that appear both in the query and the result for the top result are 'Northern Ireland'*.\n",
        "\n",
        "The rest of the top $5$ is still about money and Northern Ireland, but no longer relate to the EU, even though the similarity score is still in the range of $[0.73, 0.74]$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDVqr9N5eNzQ"
      },
      "source": [
        "### Religion/archeology"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMRI3SbBOjfO",
        "outputId": "a448d045-db9a-4a6c-cfd3-adc86181a660",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        }
      },
      "source": [
        "find_most_similar_claim(\"A Bible was found in depths of ocean\", claim_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>claim</th>\n",
              "      <th>pred</th>\n",
              "      <th>reviewed by</th>\n",
              "      <th>true?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>An ancient Bible, which has been found at the bottom of the ocean  is still readable.</td>\n",
              "      <td>0.748978</td>\n",
              "      <td>FACTLY</td>\n",
              "      <td>FALSE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crystallised book is a bible found at the bottom of the ocean.</td>\n",
              "      <td>0.667992</td>\n",
              "      <td>Africa Check</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Body of ancient Egyptian pharaoh “Fir’auna” miraculously preserved without any mummification despite being “inside the sea for more than 3000 years”</td>\n",
              "      <td>0.492650</td>\n",
              "      <td>Africa Check</td>\n",
              "      <td>Incorrect</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>In Shirsal village of Beed district, lava was seen coming out of the ground when bore well was drilled for 1200 feet</td>\n",
              "      <td>0.472769</td>\n",
              "      <td>FACTLY</td>\n",
              "      <td>FALSE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Says an image shows a photo of hurricane-ravaged Abaco Island in the Bahamas.</td>\n",
              "      <td>0.467003</td>\n",
              "      <td>PolitiFact</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                  claim  ...      true?\n",
              "0                                                                 An ancient Bible, which has been found at the bottom of the ocean  is still readable.  ...      FALSE\n",
              "1                                                                                        Crystallised book is a bible found at the bottom of the ocean.  ...      False\n",
              "2  Body of ancient Egyptian pharaoh “Fir’auna” miraculously preserved without any mummification despite being “inside the sea for more than 3000 years”  ...  Incorrect\n",
              "3                               In Shirsal village of Beed district, lava was seen coming out of the ground when bore well was drilled for 1200 feet     ...      FALSE\n",
              "4                                                                         Says an image shows a photo of hurricane-ravaged Abaco Island in the Bahamas.  ...      False\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AYDlJMGeTN3"
      },
      "source": [
        "This was an easy case, where the top 2 matches have scores above $0.66$ and the rest, unrelated claims were below $0.5$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcsvckuQfM-V"
      },
      "source": [
        "### Climate change"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOf0vUvLOya5",
        "outputId": "145ba00e-4ada-4cec-ca2f-135ad4c69389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "find_most_similar_claim(\"There is NO climate emergency\", claim_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>claim</th>\n",
              "      <th>pred</th>\n",
              "      <th>reviewed by</th>\n",
              "      <th>true?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Prime Minister Scott Morrison has defending his government’s action on climate change and telling the the United Nations General Assembly that the...</td>\n",
              "      <td>0.612380</td>\n",
              "      <td>AAP FactCheck</td>\n",
              "      <td>Mostly True - Mostly accurate but there is more than one error or problem.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"The vast majority of Americans believe that climate change is real and we need to do something about it.\"</td>\n",
              "      <td>0.611185</td>\n",
              "      <td>Michael Bennet</td>\n",
              "      <td>Mostly True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"I share the sense of urgency. I’m a scientist, so I recognize that we’re within 10 or 12 years of actually suffering irreversible damage (of clim...</td>\n",
              "      <td>0.608243</td>\n",
              "      <td>Andrew Yang</td>\n",
              "      <td>Deadline lacks nuance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"91% of the world’s population are exposed to air pollution above the World Health Organization’s suggested level. NONE ARE IN THE U.S.A.!\"</td>\n",
              "      <td>0.600670</td>\n",
              "      <td>FactCheck.org</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The time taken for environmental approvals has been brought down to 180 days from 600 days.</td>\n",
              "      <td>0.590571</td>\n",
              "      <td>FACTLY</td>\n",
              "      <td>TRUE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                   claim  ...                                                                       true?\n",
              "0  Prime Minister Scott Morrison has defending his government’s action on climate change and telling the the United Nations General Assembly that the...  ...  Mostly True - Mostly accurate but there is more than one error or problem.\n",
              "1                                             \"The vast majority of Americans believe that climate change is real and we need to do something about it.\"  ...                                                                 Mostly True\n",
              "2  \"I share the sense of urgency. I’m a scientist, so I recognize that we’re within 10 or 12 years of actually suffering irreversible damage (of clim...  ...                                                       Deadline lacks nuance\n",
              "3            \"91% of the world’s population are exposed to air pollution above the World Health Organization’s suggested level. NONE ARE IN THE U.S.A.!\"  ...                                                                       False\n",
              "4                                                            The time taken for environmental approvals has been brought down to 180 days from 600 days.  ...                                                                        TRUE\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-_9fYTRfVcQ"
      },
      "source": [
        "In this case, we fail to find any similar claims (they all have scores under $0.62$, although the top results are topically related."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gqCbqdNPiSe",
        "outputId": "1ee99042-13b2-491f-d485-70e80246c111",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        "find_most_similar_claim(\n",
        "    \"Current climate changes are to be expected from the cyclic behaviour \" +\n",
        "    \"of the climate system\",\n",
        "    claim_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>claim</th>\n",
              "      <th>pred</th>\n",
              "      <th>reviewed by</th>\n",
              "      <th>true?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Today’s global warming is no different from previous warming periods in Earth’s past.</td>\n",
              "      <td>0.741014</td>\n",
              "      <td>National Academies of Sciences, Engineering, and Medicine</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Extreme weather can be linked to global warming.</td>\n",
              "      <td>0.714379</td>\n",
              "      <td>National Academies of Sciences, Engineering, and Medicine</td>\n",
              "      <td>In some cases</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"The vast majority of Americans believe that climate change is real and we need to do something about it.\"</td>\n",
              "      <td>0.642089</td>\n",
              "      <td>Michael Bennet</td>\n",
              "      <td>Mostly True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The time taken for environmental approvals has been brought down to 180 days from 600 days.</td>\n",
              "      <td>0.563477</td>\n",
              "      <td>FACTLY</td>\n",
              "      <td>TRUE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Claim NASA develops rain cloud generator engine</td>\n",
              "      <td>0.562113</td>\n",
              "      <td>Fact Crescendo</td>\n",
              "      <td>FALSE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                        claim  ...          true?\n",
              "0                       Today’s global warming is no different from previous warming periods in Earth’s past.  ...          False\n",
              "1                                                            Extreme weather can be linked to global warming.  ...  In some cases\n",
              "2  \"The vast majority of Americans believe that climate change is real and we need to do something about it.\"  ...    Mostly True\n",
              "3                 The time taken for environmental approvals has been brought down to 180 days from 600 days.  ...           TRUE\n",
              "4                                                             Claim NASA develops rain cloud generator engine  ...          FALSE\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtDuJURQf8aI"
      },
      "source": [
        "We find two claims with scores above $0.70$. Especially the first result is a paraphrasing of the query sentence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3m8ccwogXJV"
      },
      "source": [
        "### State hacking of digital devices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXW4RZwnKjjN",
        "outputId": "9b1862b8-8c2e-46d0-d5a5-8399a8d2e99f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "find_most_similar_claim(\"The state can hack into any digital device\", claim_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>claim</th>\n",
              "      <th>pred</th>\n",
              "      <th>reviewed by</th>\n",
              "      <th>true?</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Claim: All computers can now be monitored by government agencies</td>\n",
              "      <td>0.703854</td>\n",
              "      <td>Fact Crescendo</td>\n",
              "      <td>Fact Crescendo Rating: True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Claim unrelated image from a random FB profile used to recirculate an old incident</td>\n",
              "      <td>0.641392</td>\n",
              "      <td>Fact Crescendo</td>\n",
              "      <td>FALSE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>EVMs hacked by JIO network</td>\n",
              "      <td>0.641277</td>\n",
              "      <td>Fact Crescendo</td>\n",
              "      <td>Fact Crescendo Rating: False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A video of Mark Zuckerberg shows him talking about controlling \"billions of people’s stolen data\" to control the future.</td>\n",
              "      <td>0.632752</td>\n",
              "      <td>Instagram post</td>\n",
              "      <td>Pants on Fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A claim that the Government of the United States has asked INEC to release the “real” figures of the 2019 Presidential Elections.</td>\n",
              "      <td>0.597490</td>\n",
              "      <td>DUBAWA</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                               claim  ...                         true?\n",
              "0                                                                   Claim: All computers can now be monitored by government agencies  ...   Fact Crescendo Rating: True\n",
              "1                                                 Claim unrelated image from a random FB profile used to recirculate an old incident  ...                         FALSE\n",
              "2                                                                                                         EVMs hacked by JIO network  ...  Fact Crescendo Rating: False\n",
              "3         A video of Mark Zuckerberg shows him talking about controlling \"billions of people’s stolen data\" to control the future.    ...                 Pants on Fire\n",
              "4  A claim that the Government of the United States has asked INEC to release the “real” figures of the 2019 Presidential Elections.  ...                         False\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKulAA8sgh-0"
      },
      "source": [
        "In our final example, we see that one claim has score above $0.7$ and is again a related claim. The other results are somewhat related, but not directly relevant to assess the query claim."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEn41WxIVia9"
      },
      "source": [
        "# Acknowledgements\n",
        "This notebook is based on work performed as part of the [**Co-inform** project](https://coinform.eu/).\n",
        "\n",
        "![](https://coinform.eu/wp-content/uploads/2018/06/EC-H2020.png)\n",
        "\n",
        "> <sub>\n",
        "Co-inform project is co-funded by Horizon 2020 – the Framework Programme for Research and Innovation (2014-2020)\n",
        "\n",
        "> <sub> H2020-SC6-CO-CREATION-2016-2017 (CO-CREATION FOR GROWTH AND INCLUSION) </sub>\n",
        "\n",
        "> <sub> Type of action: RIA (Research and Innovation action) </sub>\n",
        "\n",
        "> <sub> Proposal number: 770302 </sub>"
      ]
    }
  ]
}